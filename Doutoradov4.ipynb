{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estudos",
      "provenance": [],
      "collapsed_sections": [
        "iC5mPqA8XRMN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinemls/datasets/blob/main/Doutoradov4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importação das Bibliotecas"
      ],
      "metadata": {
        "id": "otXQBC6DXJG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('classic')\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import cv2\n",
        "\n",
        "from numpy.core.numeric import NaN\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier as mlp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.neural_network import MLPRegressor \n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.cluster import KMeans\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.tree import export_text #export the decision rules\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import six\n",
        "import sys\n",
        "sys.modules['sklearn.externals.six'] = six\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "#from sklearn.tree import DecisionTreeClassifier as tree\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# <><><><><><><><> Parâmetros <><><><><><><><>\n",
        "p_normalizacao = 0  # 0(não normalizado), 1(desvio padrão), 2(escala 0 a 1)\n",
        "\n",
        "t_discre = \"uniform\"\n",
        "#‘uniform’: All bins in each feature have identical widths.\n",
        "#‘quantile’: All bins in each feature have the same number of points.\n",
        "#‘kmeans’: Values in each bin have the same nearest center of a 1D k-means cluster.\n",
        "\n",
        "\n",
        "v_variation = 0.15\n",
        "\n",
        "num_grupos = 4      # 0(pela classe)\n",
        "\n",
        "qtd_faixas = 5      # 0(automático) \n",
        "\n",
        "n_base = \"iris\"\n",
        "\n",
        "t_sel_att = \"Regressao MLP\"\n",
        "# Regressao MLP\n",
        "# Classificador MLP\n",
        "# Mutual Info\n",
        "\n",
        "qtd_teste = 0.3 # Porcentagem de dados para teste no seletor de atributos supervisionado\n",
        "\n"
      ],
      "metadata": {
        "id": "y2aHAVeNVuOi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregamento e Preparação das Bases"
      ],
      "metadata": {
        "id": "xJLK-PiYUIM7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsuBFCtXR9RZ",
        "outputId": "747333f7-087e-4487-b8f9-c065d4f341ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========> Base Original <=========\n",
            "      sepal_length  sepal_width  petal_length  petal_width    species\n",
            "0             5.1          3.5           1.4          0.2     setosa\n",
            "1             4.9          3.0           1.4          0.2     setosa\n",
            "2             4.7          3.2           1.3          0.2     setosa\n",
            "3             4.6          3.1           1.5          0.2     setosa\n",
            "4             5.0          3.6           1.4          0.2     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           6.7          3.0           5.2          2.3  virginica\n",
            "146           6.3          2.5           5.0          1.9  virginica\n",
            "147           6.5          3.0           5.2          2.0  virginica\n",
            "148           6.2          3.4           5.4          2.3  virginica\n",
            "149           5.9          3.0           5.1          1.8  virginica\n",
            "\n",
            "[150 rows x 5 columns]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "=========> Base Modificada <=========\n",
            "      sepal_length  sepal_width  petal_length  petal_width\n",
            "0             5.1          3.5           1.4          0.2\n",
            "1             4.9          3.0           1.4          0.2\n",
            "2             4.7          3.2           1.3          0.2\n",
            "3             4.6          3.1           1.5          0.2\n",
            "4             5.0          3.6           1.4          0.2\n",
            "..            ...          ...           ...          ...\n",
            "145           6.7          3.0           5.2          2.3\n",
            "146           6.3          2.5           5.0          1.9\n",
            "147           6.5          3.0           5.2          2.0\n",
            "148           6.2          3.4           5.4          2.3\n",
            "149           5.9          3.0           5.1          1.8\n",
            "\n",
            "[150 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "trans = MinMaxScaler()\n",
        "\n",
        "if n_base == \"iris\":\n",
        "  bb = sns.load_dataset(n_base)\n",
        "\n",
        "if n_base == 'seeds':\n",
        "  bb = pd.read_csv(\"/content/drive/MyDrive/bases/seeds.csv\",sep=\",\")\n",
        "\n",
        "if n_base == 'glass':\n",
        "  bb = pd.read_csv(\"/content/drive/MyDrive/bases/glass.csv\",sep=\",\")\n",
        "\n",
        "if n_base == 'wine':\n",
        "  bb = pd.read_csv(\"/content/drive/MyDrive/bases/wine.csv\",sep=\",\")\n",
        "\n",
        "if n_base == 'cancer_mama':\n",
        "  bb = pd.read_csv(\"/content/drive/MyDrive/bases/cancermama.csv\",sep=\",\")\n",
        "  bb = bb.iloc[: , :-1]\n",
        "  col_list = list(bb)\n",
        "  columns_titles = ['id', 'fractal_dimension_worst', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'diagnosis']\n",
        "  bb=bb.reindex(columns=columns_titles)\n",
        "\n",
        "\n",
        "#pin = sns.load_dataset('penguins')\n",
        "#iris.head()\n",
        "#pin.head()\n",
        "#pin.tail()\n",
        "base_original = bb\n",
        "print(\"=========> Base Original <=========\\n\",base_original)\n",
        "\n",
        "#print(\"Descrição dos Dados:\\n\", base_original.describe())\n",
        "\n",
        "# --> Remove nulls <--\n",
        "data = base_original.dropna()\n",
        "data = data.reset_index(drop = True)\n",
        "\n",
        "\n",
        "if(num_grupos == 0): #<><><><><> Se a classe for o grupo <><><><><><>\n",
        "  #print(data.columns[-1])\n",
        "  #data[data.columns[-1]] = data[data.columns[-1]].map({0:'X'}, na_action='ignore')\n",
        "  data[data.columns[-1]].replace(0, 'X', inplace = True)\n",
        "  att_classe = data.iloc[: , -1]\n",
        "  att_classe = att_classe.unique()\n",
        "  qtd_classes = 0\n",
        "  for item in att_classe:\n",
        "    #print(item,i)\n",
        "    #data.replace(to_replace=item, value=str(i))\n",
        "    #data[\"species\"].replace(\"setosa\",\"kjkj\", regex=True)\n",
        "    data[data.columns[-1]].replace({item: qtd_classes}, inplace=True)\n",
        "    qtd_classes = qtd_classes + 1\n",
        "  data.columns = [*data.columns[:-1], 'grupo']\n",
        "else:\n",
        "  # --> Apagar Colunas classe <--\n",
        "  if num_grupos > 0:\n",
        "    #att_classe = \"species\"\n",
        "    data = data.iloc[: , :-1] # Apaga o atributo classe (última coluna)\n",
        "\n",
        "\n",
        "# Apaga o atributo ID\n",
        "if 'ID' in data.columns:    \n",
        "  data = data.drop(columns=[\"ID\"]) \n",
        "if 'id' in data.columns: \n",
        "  data = data.drop(columns=[\"id\"]) \n",
        "\n",
        "base_original = data\n",
        "\n",
        "# --> Normalização <--\n",
        "colunas = list(data.columns.values)\n",
        "#print (colunas) \n",
        "n_normalizacao = \"Sem Normalização\"\n",
        "if(p_normalizacao == 1):\n",
        "  data = scaler.fit_transform(data)\n",
        "  n_normalizacao = \"Desvio Padrão\"\n",
        "if(p_normalizacao == 2):\n",
        "  data = trans.fit_transform(data)\n",
        "  n_normalizacao = \"Escala 0-1\"\n",
        "\n",
        "data = pd.DataFrame(data, columns = colunas)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"=========> Base Modificada <=========\\n\",data)\n",
        "#print(\"Descrição dos Dados:\\n\", data.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uso do K-Means"
      ],
      "metadata": {
        "id": "2BCL46jC_HkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if(num_grupos != 0): #<><><><><> Se a classe for o grupo <><><><><><>\n",
        "\n",
        "  grupos = KMeans(num_grupos, random_state=0).fit(data)\n",
        "\n",
        "  data = base_original\n",
        "\n",
        "  data['grupo'] = grupos.labels_ # Cria uma coluna com o grupo de cada registro\n",
        "  print(\"====> Base com Grupos <====\\n\\n\",data)\n",
        "\n",
        "print('Quantidade de Registros em cada Grupo:\\n', data['grupo'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE0fkem-_LUr",
        "outputId": "6d5d0577-b804-4d8c-a120-30ff75cd7235"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====> Base com Grupos <====\n",
            "\n",
            "      sepal_length  sepal_width  petal_length  petal_width  grupo\n",
            "0             5.1          3.5           1.4          0.2      1\n",
            "1             4.9          3.0           1.4          0.2      1\n",
            "2             4.7          3.2           1.3          0.2      1\n",
            "3             4.6          3.1           1.5          0.2      1\n",
            "4             5.0          3.6           1.4          0.2      1\n",
            "..            ...          ...           ...          ...    ...\n",
            "145           6.7          3.0           5.2          2.3      2\n",
            "146           6.3          2.5           5.0          1.9      3\n",
            "147           6.5          3.0           5.2          2.0      3\n",
            "148           6.2          3.4           5.4          2.3      2\n",
            "149           5.9          3.0           5.1          1.8      3\n",
            "\n",
            "[150 rows x 5 columns]\n",
            "Quantidade de Registros em cada Grupo:\n",
            " 1    50\n",
            "3    40\n",
            "2    32\n",
            "0    28\n",
            "Name: grupo, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Seleção de Atributos**"
      ],
      "metadata": {
        "id": "Jy9-fZMrn6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (t_sel_att == \"Classificador MLP\") or (t_sel_att == \"Regressao MLP\"):\n",
        "\n",
        "  v_grupo = []\n",
        "  v_attr = []\n",
        "  v_accu = []\n",
        "\n",
        "  t_grupos = data['grupo'].unique()\n",
        "  qtd_grupos = len(t_grupos)\n",
        "  #print(qtd_grupos)\n",
        "\n",
        "  ##### Para cada Grupo #####\n",
        "  for iGrupos in t_grupos:    \n",
        "    #print(\"\\n\\n############ Grupo: \", iGrupos, \" ############\")\n",
        "    base = data.query(\"grupo == \"+str(iGrupos))\n",
        "    base = base.drop(columns=['grupo']) # Apaga o grupo\n",
        "    #print(base)\n",
        "\n",
        "\n",
        "    qtd_col = data.columns.size - 1   \n",
        "    ##### Para cada coluna #####\n",
        "    for i_col in range(0, qtd_col):\n",
        "\n",
        "      treino, teste = train_test_split(base, test_size = qtd_teste)\n",
        "      Y_train = treino.iloc[:, i_col]\n",
        "      Y_teste = teste.iloc[:, i_col]\n",
        "      X_train = treino.drop(treino.columns[i_col], axis=1)\n",
        "      X_teste = teste.drop(teste.columns[i_col], axis=1)\n",
        "      #print(X_train)\n",
        "      #print(Y_train)\n",
        "\n",
        "      #### Predição\n",
        "      if t_sel_att == \"Classificador MLP\":\n",
        "        \n",
        "        atributo = Y_train.name\n",
        "        Y_train = np.asarray(Y_train, dtype=\"int_\")\n",
        "        \n",
        "        #print(Y_train)\n",
        "        #X_teste = np.asarray(X_teste, dtype=\"int_\")\n",
        "        \n",
        "        clp = mlp(solver='sgd', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
        "        clp.fit(X_train,Y_train)\n",
        "        Y_pred = clp.predict(X_teste)\n",
        "        Y_teste = np.asarray(Y_teste, dtype=\"int_\")\n",
        "        \n",
        "        cm = confusion_matrix(Y_pred, Y_teste)\n",
        "        acuracia = accuracy(cm)\n",
        "\n",
        "      #### Regressão  \n",
        "      if t_sel_att == \"Regressao MLP\":\n",
        "        \n",
        "        atributo = Y_train.name\n",
        "\n",
        "        model = MLPRegressor(solver='lbfgs',alpha=0.001,hidden_layer_sizes=(3,2))\n",
        "        model.fit(X_train,Y_train)\n",
        "        Y_pred = model.predict(X_teste)\n",
        "\n",
        "        #print(\"Score : \", model.score(X_teste, Y_teste))\n",
        "        \n",
        "        #acuracia = 1-metrics.mean_squared_log_error(Y_teste, Y_pred)\n",
        "        #acuracia = 1-metrics.mean_absolute_percentage_error(Y_teste, Y_pred)\n",
        "        acuracia = 1-metrics.mean_squared_error(Y_teste, Y_pred)\n",
        "        \n",
        "        #print(\"Acerto médio de \", Y_train.name, \": \", acuracia)\n",
        "\n",
        "      v_grupo.append(iGrupos)\n",
        "      v_attr.append(atributo)\n",
        "      v_accu.append(acuracia)\n",
        "\n",
        "\n",
        "      ##### Fim para cada coluna #####\n",
        "\n",
        "\n",
        "    ##### Fim para cada Grupo #####\n",
        "\n",
        "  #coloca os resultados em uma matriz \n",
        "  v_resul = np.array([v_grupo, v_attr, v_accu])\n",
        "  v_resul = v_resul.T\n",
        "  v_resul = pd.DataFrame(v_resul, columns = [ 'grupo', 'atrib', 'accu' ])\n",
        "  #v_resul = v_resul.reset_index()\n",
        "  v_resul[\"accu\"] = pd.to_numeric(v_resul[\"accu\"])\n",
        "  v_resul[\"grupo\"] = pd.to_numeric(v_resul[\"grupo\"])\n",
        "\n",
        "  print(v_resul)\n",
        "\n",
        "if (t_sel_att == \"Mutual Info\"):\n",
        "  from sklearn.feature_selection import mutual_info_classif\n",
        "  l_atrib = data.columns.to_list()\n",
        "  l_atrib.pop()\n",
        "  X = data.drop(columns=['grupo'])\n",
        "  #print(X)\n",
        "  y = data[\"grupo\"]\n",
        "  l_rank = mutual_info_classif(X, y, discrete_features=True)\n",
        "  t_grupos = data['grupo'].unique()\n",
        "  v_resul_f = []\n",
        "  v_grupo_f = []\n",
        "  v_attr_f = []\n",
        "  v_accu_f = []\n",
        "  count = 0\n",
        "  g = 0\n",
        "  for g in range(len(t_grupos)):\n",
        "    #print(\"Grupo-->\", t_grupos[g])\n",
        "    for r in range(len(l_rank)):\n",
        "      #print(\"Grupo: \", t_grupos[g], \"Atributo: \", l_atrib[r], \"Rank: \", l_rank[r])\n",
        "      v_grupo_f.append(t_grupos[g])\n",
        "      v_attr_f.append(l_atrib[r])\n",
        "      v_accu_f.append(l_rank[r])\n",
        "      #v_grupo_f[count] = t_grupos[g]\n",
        "      #v_resul_f[count] = [g, l_atrib[r], l_rank[r]]\n",
        "    #  print(count)\n",
        "    #  v_resul_f[0] = [1, \"sdsda\", 8234]\n",
        "      count = count + 1\n",
        "\n",
        "  v_resul_f = np.array([v_grupo_f, v_attr_f, v_accu_f])\n",
        "  v_resul_f = v_resul_f.T\n",
        "  v_resul_f = pd.DataFrame(v_resul_f, columns = [ 'grupo', 'atrib', 'accu' ])\n",
        "  #v_resul = v_resul.reset_index()\n",
        "  v_resul_f[\"accu\"] = pd.to_numeric(v_resul_f[\"accu\"])\n",
        "  v_resul_f[\"grupo\"] = pd.to_numeric(v_resul_f[\"grupo\"])\n",
        "  v_resul = v_resul_f\n",
        "  print (v_resul)"
      ],
      "metadata": {
        "id": "oAtjX4I4ofQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04aa9a4-8a49-45d7-88a0-9c37467b44e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    grupo         atrib      accu\n",
            "0       1  sepal_length  0.924474\n",
            "1       1   sepal_width  0.802612\n",
            "2       1  petal_length  0.955698\n",
            "3       1   petal_width  0.984193\n",
            "4       3  sepal_length  0.812331\n",
            "5       3   sepal_width  0.958431\n",
            "6       3  petal_length  0.979679\n",
            "7       3   petal_width  0.900062\n",
            "8       0  sepal_length  0.884423\n",
            "9       0   sepal_width  0.976054\n",
            "10      0  petal_length  0.914866\n",
            "11      0   petal_width  0.953906\n",
            "12      2  sepal_length  0.801504\n",
            "13      2   sepal_width  0.905900\n",
            "14      2  petal_length  0.880064\n",
            "15      2   petal_width  0.951736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotulação Baseada em Lopes"
      ],
      "metadata": {
        "id": "UtzmG7qIzDPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy(confusion_matrix):\n",
        "   diagonal_sum = confusion_matrix.trace()\n",
        "   sum_of_all_elements = confusion_matrix.sum()\n",
        "   return (diagonal_sum / sum_of_all_elements)*100\n",
        "\n",
        "#print(data)\n",
        "print('\\033[1m', \"<><><><><><> Parâmetros <><><><><><><>\", '\\033[0m')\n",
        "print(\"Nome da Base:\", n_base)\n",
        "print(\"Tipo de Normalização:\", n_normalizacao)\n",
        "print(\"Variação V:\", v_variation)\n",
        "if (num_grupos == 0):\n",
        "  print(\"Número de Grupos(formados pela classe):\", qtd_classes)\n",
        "else:\n",
        "  print(\"Número de Grupos(k):\", num_grupos)\n",
        "print(\"Quantidade de Faixas:\", qtd_faixas)\n",
        "print(\"Seleção de Atributos:\", t_sel_att)\n",
        "\n",
        "\n",
        "\n",
        "#<><><><><> Discretização <><><><><>\n",
        "base = data.drop(columns=['grupo']) # Apaga o grupo\n",
        "col_grupo = data[\"grupo\"]\n",
        "col_nomes = list(base.columns)\n",
        "\n",
        "enc = KBinsDiscretizer(n_bins=qtd_faixas, strategy=t_discre, encode=\"ordinal\")\n",
        "base_d = enc.fit_transform(base)\n",
        "base_d = pd.DataFrame(base_d,columns=col_nomes) \n",
        "base_d['grupo'] = col_grupo\n",
        "\n",
        "#print(base_d)\n",
        "\n",
        "\n",
        "#pega os atributos com acurácia até v_variation pior \n",
        "t_grupos = v_resul['grupo'].unique()\n",
        "#print(t_grupos)\n",
        "print('\\033[1m', \"\\n<><><><><><><> Rótulos <><><><><><><>\", '\\033[0m')\n",
        "iGrupos = 0\n",
        "count = 0\n",
        "##### Para cada Grupo #####\n",
        "for iGrupos in t_grupos: \n",
        "  r_base = v_resul.query(\"grupo == \"+str(iGrupos))\n",
        "  #print(\"\\nr_base:\", r_base)\n",
        "  #print(\"\\nBase_d:\\n\", base_d)\n",
        "  print(\"\\n===> Grupo \"+str(iGrupos), \"(\", data['grupo'].value_counts()[count],\"elementos)\")\n",
        "  count = count+1\n",
        "  #print(r_base)\n",
        "  #best_att = r_base.loc[r_base['accu'] == r_base[\"accu\"].max()]\n",
        "  print(r_base[\"accu\"].max())\n",
        "  print((r_base[\"accu\"].max()*v_variation))\n",
        "  print((r_base[\"accu\"].max())-(r_base[\"accu\"].max()*v_variation))\n",
        "  best_att = r_base.loc[r_base['accu'] >= r_base[\"accu\"].max()-(r_base[\"accu\"].max()*v_variation)]\n",
        "  #print(r_base[\"accu\"].max()-(r_base[\"accu\"].max()*v_variation))\n",
        "  \n",
        "  #print(best_att)\n",
        "  #print(\"\\nBest_att:\\n\", best_att, \"\\n\")\n",
        "\n",
        "  for i in best_att.index:\n",
        "    print(\"Atributo: \", best_att[\"atrib\"][i] , \"(\",best_att[\"accu\"][i],\")\")\n",
        "    r_base = base_d.query(\"grupo == \"+str(iGrupos))\n",
        "    #print(\"\\nr_base:\\n\", r_base)\n",
        "    faixas = enc.bin_edges_[r_base.columns.get_loc(best_att[\"atrib\"][i])] \n",
        "    melhor_faixa = r_base[best_att[\"atrib\"][i]].value_counts()\n",
        "\n",
        "    #print(r_base)\n",
        "    acertos = r_base[best_att[\"atrib\"][i]].value_counts().tolist()\n",
        "    #print (\"Acertos:\", acertos)\n",
        "    \n",
        "    index = melhor_faixa.index\n",
        "    indexNamesArr = melhor_faixa.index.values\n",
        "    l_inter = list(indexNamesArr)\n",
        "    indice_melhor = int(l_inter[0])\n",
        "    \n",
        "    tx_acerto = (acertos[0]*100)/len(r_base.index)\n",
        "\n",
        "    print(\"Faixa: \", faixas[indice_melhor], \"-\", faixas[indice_melhor+1], \"(\", tx_acerto,\")\")\n",
        "    \n",
        "    \n",
        "    #print(len(r_base.index))\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "##### Fim para cada Grupo #####\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1m1XdLO2zISj",
        "outputId": "7a552a0d-5991-42c1-a671-b88e324ec684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m <><><><><><> Parâmetros <><><><><><><> \u001b[0m\n",
            "Nome da Base: iris\n",
            "Tipo de Normalização: Sem Normalização\n",
            "Variação V: 0.15\n",
            "Número de Grupos(k): 4\n",
            "Quantidade de Faixas: 5\n",
            "Seleção de Atributos: Regressao MLP\n",
            "\u001b[1m \n",
            "<><><><><><><> Rótulos <><><><><><><> \u001b[0m\n",
            "\n",
            "===> Grupo 1 ( 28 elementos)\n",
            "0.9841931974818487\n",
            "0.1476289796222773\n",
            "0.8365642178595715\n",
            "Atributo:  sepal_length ( 0.9244740437231908 )\n",
            "Faixa:  4.3 - 5.02 ( 56.0 )\n",
            "Atributo:  petal_length ( 0.9556984522235294 )\n",
            "Faixa:  1.0 - 2.18 ( 100.0 )\n",
            "Atributo:  petal_width ( 0.9841931974818487 )\n",
            "Faixa:  0.1 - 0.58 ( 98.0 )\n",
            "\n",
            "===> Grupo 3 ( 50 elementos)\n",
            "0.9796785777322408\n",
            "0.1469517866598361\n",
            "0.8327267910724047\n",
            "Atributo:  sepal_width ( 0.9584311228411624 )\n",
            "Faixa:  2.48 - 2.96 ( 52.5 )\n",
            "Atributo:  petal_length ( 0.9796785777322408 )\n",
            "Faixa:  4.540000000000001 - 5.720000000000001 ( 77.5 )\n",
            "Atributo:  petal_width ( 0.9000623820991087 )\n",
            "Faixa:  1.06 - 1.54 ( 52.5 )\n",
            "\n",
            "===> Grupo 0 ( 32 elementos)\n",
            "0.976054270105559\n",
            "0.14640814051583384\n",
            "0.8296461295897252\n",
            "Atributo:  sepal_length ( 0.8844228989353713 )\n",
            "Faixa:  5.02 - 5.74 ( 64.28571428571429 )\n",
            "Atributo:  sepal_width ( 0.976054270105559 )\n",
            "Faixa:  2.48 - 2.96 ( 57.142857142857146 )\n",
            "Atributo:  petal_length ( 0.9148660441675704 )\n",
            "Faixa:  3.3600000000000003 - 4.540000000000001 ( 89.28571428571429 )\n",
            "Atributo:  petal_width ( 0.9539058167048337 )\n",
            "Faixa:  1.06 - 1.54 ( 71.42857142857143 )\n",
            "\n",
            "===> Grupo 2 ( 40 elementos)\n",
            "0.9517355396884104\n",
            "0.14276033095326154\n",
            "0.8089752087351488\n",
            "Atributo:  sepal_width ( 0.9058998562002426 )\n",
            "Faixa:  2.96 - 3.4400000000000004 ( 65.625 )\n",
            "Atributo:  petal_length ( 0.8800641177574755 )\n",
            "Faixa:  5.720000000000001 - 6.9 ( 50.0 )\n",
            "Atributo:  petal_width ( 0.9517355396884104 )\n",
            "Faixa:  2.02 - 2.5 ( 68.75 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotulação Baseada em Árvore"
      ],
      "metadata": {
        "id": "X9akhgFmsHUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_saida_arv = 1 # 1 --> Grafica  // 0 --> Texto\n",
        "\n",
        "#print(data)\n",
        "\n",
        "if qtd_faixas != 0:\n",
        "#<><><><><> Discretização <><><><><>\n",
        "  base = data.drop(columns=['grupo']) # Apaga o grupo\n",
        "  col_grupo = data[\"grupo\"]\n",
        "  col_nomes = list(base.columns)\n",
        "\n",
        "  enc = KBinsDiscretizer(n_bins=qtd_faixas, strategy=t_discre, encode=\"ordinal\")\n",
        "  base_d = enc.fit_transform(base)\n",
        "  base_d = pd.DataFrame(base_d,columns=col_nomes) \n",
        "  base_d['grupo'] = col_grupo\n",
        "\n",
        "  #base_d.apply(base_d.to_numeric, errors='ignore')\n",
        "  base_d = base_d.astype(str)\n",
        "\n",
        "  data = base_d\n",
        "  print(\"dados:\\n\",data)\n",
        "  print(data.info())\n",
        "\n",
        "\n",
        "i_col = data.columns.size \n",
        "\n",
        "print(i_col-1)\n",
        "\n",
        "treino, teste = train_test_split(data, test_size = qtd_teste)\n",
        "Y_train = treino.iloc[:, i_col-1]\n",
        "Y_teste = teste.iloc[:, i_col-1]\n",
        "X_train = treino.drop(treino.columns[i_col-1], axis=1)\n",
        "X_teste = teste.drop(teste.columns[i_col-1], axis=1)\n",
        "\n",
        "# Create Decision Tree classifer object\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clf = KMeans.fit(X_train,Y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = clf.predict(X_teste)\n",
        "\n",
        "print(\"\\nAcurácia da Árvore:\",metrics.accuracy_score(Y_teste, y_pred), \"\\n\")\n",
        "\n",
        "\n",
        "feature_cols = X_teste.columns.to_list()\n",
        "class_names = Y_teste.unique()\n",
        "\n",
        "if(t_saida_arv == 1):\n",
        "  \n",
        "  acs = [str(x) for x in class_names]\n",
        "  dot_data = StringIO()\n",
        "  export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True,feature_names = feature_cols,class_names=acs)\n",
        "  graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "  graph.write_png(n_base+'.png')\n",
        "  Image(graph.create_png())\n",
        "  \n",
        "  img = cv2.imread(n_base+'.png')\n",
        "  cv2_imshow(img)\n",
        "\n",
        "else:\n",
        "  tree_rules = export_text(clf, feature_names = feature_cols) #print the result\n",
        "  print(tree_rules)\n",
        "\n",
        "print(feature_cols[clf.tree_.feature[0]])\n",
        "print(clf.tree_.threshold[0])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "NVbuhM7GsVoW",
        "outputId": "ff59370b-036a-4d0b-9544-3e8f6ca85b17"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dados:\n",
            "     sepal_length sepal_width petal_length petal_width grupo\n",
            "0            1.0         3.0          0.0         0.0     1\n",
            "1            0.0         2.0          0.0         0.0     1\n",
            "2            0.0         2.0          0.0         0.0     1\n",
            "3            0.0         2.0          0.0         0.0     1\n",
            "4            0.0         3.0          0.0         0.0     1\n",
            "..           ...         ...          ...         ...   ...\n",
            "145          3.0         2.0          3.0         4.0     2\n",
            "146          2.0         1.0          3.0         3.0     3\n",
            "147          3.0         2.0          3.0         3.0     3\n",
            "148          2.0         2.0          3.0         4.0     2\n",
            "149          2.0         2.0          3.0         3.0     3\n",
            "\n",
            "[150 rows x 5 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   sepal_length  150 non-null    object\n",
            " 1   sepal_width   150 non-null    object\n",
            " 2   petal_length  150 non-null    object\n",
            " 3   petal_width   150 non-null    object\n",
            " 4   grupo         150 non-null    object\n",
            "dtypes: object(5)\n",
            "memory usage: 6.0+ KB\n",
            "None\n",
            "4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6aed9ed6de64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Train Decision Tree Classifer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#Predict the response for test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[0;32m-> 1137\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1138\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '_validate_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plotagem de Gráficos"
      ],
      "metadata": {
        "id": "iC5mPqA8XRMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # x = pin['bill_depth_mm']\n",
        " # y = pin['bill_length_mm']\n",
        "x = data['grupo']\n",
        "y = data[\"petal_width\"]\n",
        "z = data['petal_length']\n",
        "\n",
        "#sns.scatterplot(y,z) # ---> Gráfico Comum\n",
        "# plt.pie(x) # ---> Gráfico em Pizza\n",
        "\n",
        "fig = plt.figure(figsize=(10,10))\n",
        "ax = Axes3D(fig)\n",
        "ax.scatter(x, y, z, marker='o')\n",
        "\n",
        "ax.set_xlabel(x.name)\n",
        "ax.set_ylabel(y.name)\n",
        "ax.set_zlabel(z.name)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# sns.pairplot(data, hue=\"grupo\")"
      ],
      "metadata": {
        "id": "WSFKmwTDzleL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vKQCEyPnzGv-"
      }
    }
  ]
}